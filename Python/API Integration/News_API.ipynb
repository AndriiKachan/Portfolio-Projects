{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News API Integration with Python\n",
    "\n",
    "This Python code demonstrates how to connect to the [News API](https://newsapi.org/) and fetch top headlines from the United States. The code uses the **Requests** library to fetch the data and then processes the articles, printing the title, source, description, and URL of each article.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Python** installed on the machine.\n",
    "- **News API Key** from [News API](https://newsapi.org/).\n",
    "- **Requests** library installed:\n",
    "  ```bash\n",
    "  pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_key = 'API_Key'\n",
    "\n",
    "def get_top_headlines():\n",
    "    url = f'https://newsapi.org/v2/top-headlines?country=us&apiKey={api_key}'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data['articles']\n",
    "        \n",
    "        for article in articles:\n",
    "            print(f\"Title: {article['title']}\")\n",
    "            print(f\"Source: {article['source']['name']}\")\n",
    "            print(f\"Description: {article['description']}\")\n",
    "            print(f\"URL: {article['url']}\")\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "get_top_headlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced News API Integration with Python\n",
    "\n",
    "This code demonstrates how to integrate News API with advanced features such as keyword-based search, sentiment analysis, category-based headlines, date range filtering, and pagination.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Python** installed on your machine.\n",
    "2. **News API Key** from [News API](https://newsapi.org/).\n",
    "3. **TextBlob** library for sentiment analysis:\n",
    "   ```bash\n",
    "   pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from textblob import TextBlob\n",
    "\n",
    "api_key = 'API-Key'\n",
    "\n",
    "# Function to get news articles by a keyword search\n",
    "def get_news_by_keyword(keyword, page_size=5, page=1):\n",
    "    # Forming the API URL based on the provided keyword and pagination\n",
    "    url = f'https://newsapi.org/v2/everything?q={keyword}&pageSize={page_size}&page={page}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # If the request was successful (HTTP Status Code 200)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON format\n",
    "        articles = data['articles']  # Extract articles from the response\n",
    "        \n",
    "        # Loop through each article and display its details\n",
    "        for article in articles:\n",
    "            print(f\"Title: {article['title']}\")\n",
    "            print(f\"Source: {article['source']['name']}\")\n",
    "            print(f\"Description: {article['description']}\")\n",
    "            print(f\"URL: {article['url']}\")\n",
    "            print(f\"Published at: {article['publishedAt']}\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # Analyze sentiment of the article's title + description\n",
    "            sentiment = analyze_sentiment(article['title'] + \" \" + article['description'])\n",
    "            print(f\"Sentiment: {'Positive' if sentiment > 0 else 'Negative' if sentiment < 0 else 'Neutral'}\")\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        # In case of an error, print the HTTP status code\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "# Function to analyze sentiment of the text using TextBlob\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)  # Create a TextBlob object with the text\n",
    "    return blob.sentiment.polarity  # Return sentiment polarity (-1 to 1)\n",
    "\n",
    "# Function to get top headlines by category (e.g., business, sports)\n",
    "def get_top_headlines_by_category(category='general', page_size=5, page=1):\n",
    "    # API call to fetch top headlines based on category\n",
    "    url = f'https://newsapi.org/v2/top-headlines?category={category}&pageSize={page_size}&page={page}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON format\n",
    "        articles = data['articles']  # Extract articles\n",
    "        \n",
    "        # Loop through each article and display its details\n",
    "        for article in articles:\n",
    "            print(f\"Title: {article['title']}\")\n",
    "            print(f\"Source: {article['source']['name']}\")\n",
    "            print(f\"Description: {article['description']}\")\n",
    "            print(f\"URL: {article['url']}\")\n",
    "            print(f\"Published at: {article['publishedAt']}\")\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "# Function to get news articles based on a specific date range\n",
    "def get_news_by_date_range(start_date, end_date, page_size=5, page=1):\n",
    "    # Form URL for API with the given date range\n",
    "    url = f'https://newsapi.org/v2/everything?from={start_date}&to={end_date}&pageSize={page_size}&page={page}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert response to JSON\n",
    "        articles = data['articles']  # Extract articles\n",
    "        \n",
    "        # Loop through articles and print out their details\n",
    "        for article in articles:\n",
    "            print(f\"Title: {article['title']}\")\n",
    "            print(f\"Source: {article['source']['name']}\")\n",
    "            print(f\"Description: {article['description']}\")\n",
    "            print(f\"URL: {article['url']}\")\n",
    "            print(f\"Published at: {article['publishedAt']}\")\n",
    "            print(\"=\"*50)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "# Function to get multiple pages of news articles (pagination)\n",
    "def get_paginated_news(keyword, total_pages=3, page_size=5):\n",
    "    for page in range(1, total_pages+1):\n",
    "        print(f\"Fetching page {page} of {total_pages}...\")\n",
    "        get_news_by_keyword(keyword, page_size=page_size, page=page)\n",
    "\n",
    "# Example calls\n",
    "keyword = \"stock market\"  # Search for news about the stock market\n",
    "get_news_by_keyword(keyword, page_size=5, page=1)\n",
    "\n",
    "category = \"business\"  # Fetch top business news\n",
    "get_top_headlines_by_category(category, page_size=5, page=1)\n",
    "\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2025-01-01\"\n",
    "get_news_by_date_range(start_date, end_date, page_size=5, page=1)\n",
    "\n",
    "get_paginated_news(\"technology\", total_pages=3, page_size=5)  # Paginate through tech news\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
